
## Papers on Robust Machine Learning

### Adversarial Examples
* [Szegedy et al., 2014: Intriguing properties of neural networks](https://arxiv.org/pdf/1312.6199.pdf),
the first paper to introduce adversarial examples
* [Moosavi-Dezfooli et al., 2016: DeepFool: a simple and accurate method to fool deep neural netwoks](https://arxiv.org/pdf/1511.04599.pdf), develops gradient descent like and Newton's method like ways of finding adversarial examples
* [Carlini et al., 2017: Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods](https://arxiv.org/abs/1705.07263)

#### Transferability
* [Tramer et al., 2017: The Space of Transferable Adversarial Examples](https://arxiv.org/abs/1704.03453)
* [Mohsen et al., 2016: Universal adversarial perturbations](https://arxiv.org/abs/1610.08401), aggregate minimal perturbations from multiple classifiers, quite empirical
* [Fawzi et al., 2018: Adversarial vulnerability for any classifier](https://arxiv.org/abs/1802.08686)

### GAN
* [Goodfellow et al., 2014: Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf), the first paper to introduce GAN

#### WGAN
* [Arjovsky et al., 2017: Wasserstein GAN](https://arxiv.org/abs/1701.07875), use EM distance instead of JS divergence for more stable GAN training

#### Convergence
* [Daskalakis et al., 2017: Training GANs with Optimism](https://arxiv.org/abs/1711.00141)
* [Grnarova et al., 2017: An Online Learning Approach to Generative Adversarial Networks](https://arxiv.org/abs/1706.03269)

### Differential Privacy
* [Abadi et al., 2016: Deep Learning with Differential Privacy](https://arxiv.org/abs/1607.00133)
* [Papernot et al., 2017: Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data](https://arxiv.org/abs/1610.05755)

### Understanding Deep Learning
* [Koh et al., 2017: Understanding Black-box Predictions via Influence Functions](https://arxiv.org/abs/1703.04730)
* [Zhang et al., 2018: Visual Interpretability for Deep Learning: a Survey](https://arxiv.org/abs/1802.00614)
* [Narayanan et al., 2018: How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation](https://arxiv.org/abs/1802.00682?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=piqcy)

### Generalization
* [Zhang et al., 2016: Understanding deep learning requires rethinking generalization](https://arxiv.org/abs/1611.03530)
